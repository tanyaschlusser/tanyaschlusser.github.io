<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Tanya Schlusser (Posts about iterative)</title><link>https://tanyaschlusser.github.io/</link><description></description><atom:link href="https://tanyaschlusser.github.io/categories/iterative.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2018 &lt;a href="mailto:tanya@tickel.net"&gt;Tanya Schlusser&lt;/a&gt; </copyright><lastBuildDate>Thu, 11 Oct 2018 19:03:52 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Bayesian updating and the NFL</title><link>https://tanyaschlusser.github.io/posts/bayesian-updating-and-the-nfl/</link><dc:creator>Tanya Schlusser</dc:creator><description>&lt;figure&gt;&lt;img src="https://tanyaschlusser.github.io/posts/bayesian-updating-and-the-nfl/home_spreads.png"&gt;&lt;/figure&gt; &lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;It's football season again, hooray! Every year for my friends' football pool I try out a different algorithm. Invariably, my picks are around 60% accurate. Not terrible, but according to NFL Pickwatch (&lt;a href="https://web.archive.org/web/20180811195907/http://nflpickwatch.com/"&gt;archive&lt;/a&gt;, &lt;a href="https://nflpickwatch.com/"&gt;current season&lt;/a&gt;), the best pickers get to 68 or 69%. So, an amazing performance—my upper bound—is just under 70%, and the lower bound for a competitive model—the FiveThirtyEight baseline—is 60%.&lt;/p&gt;
&lt;p&gt;I've been modeling NFL outcomes for a couple of years, and running linear (predicting point spread) and logistic (predicting win probability) regressions given various team and player data. My best year so far incorporated the Vegas spread into the model, and my biggest disaster so far was an aggressive lasso model on every player in every offensive line, with team defenses lumped as a group. Attempting to track &lt;a href="https://www.pro-football-reference.com/players/injuries.htm"&gt;injuries&lt;/a&gt;, suspensions, and other changes to the starting lineup was not sustainable for the amount of time I wanted to spend.&lt;/p&gt;
&lt;p&gt;Enter Nate Silver's awesome &lt;span class="vocabulary" title="Arpad Elo was a Hungarian-American physics professor who invented the system to rank chess players. Silver adapted it for Football, baseball, and most of the other sports on FiveThirtyEight."&gt;&lt;a href="https://fivethirtyeight.com/features/how-our-2017-nfl-predictions-work/"&gt;NFL Elo rankings&lt;/a&gt;&lt;/span&gt;, the aspirational target for this year. What's impressive is that he gets something like 60% accuracy out of literally no information but home field advantage and past scores. I particularly love that it updates weekly to incorporate the new information—this immediately says "Bayesian" and in fact is a lot how people using their intuition are making their picks anyway. A system like his—but with a more straightforward Bayesian model—is the goal of this post.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://tanyaschlusser.github.io/posts/bayesian-updating-and-the-nfl/"&gt;Read more&lt;/a&gt; (25 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>a/b testing</category><category>bayesian</category><category>feature engineering</category><category>iterative</category><category>nfl</category><guid>https://tanyaschlusser.github.io/posts/bayesian-updating-and-the-nfl/</guid><pubDate>Sun, 09 Sep 2018 05:00:42 GMT</pubDate></item></channel></rss>