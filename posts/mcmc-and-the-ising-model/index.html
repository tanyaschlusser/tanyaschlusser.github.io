<!DOCTYPE html>
<html prefix="            og: http://ogp.me/ns# article: http://ogp.me/ns/article#     " vocab="http://ogp.me/ns" lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="The Metropolis-Hastings method using both PyMC3 and standard techniques, demonstrated via the Ising model.">
<meta name="viewport" content="width=device-width">
<title>MCMC and the Ising Model | Tanya Schlusser</title>
<link href="../../assets/css/custom.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" href="../../rss.xml">
<link rel="canonical" href="https://tanyaschlusser.github.io/posts/mcmc-and-the-ising-model/">
<link rel="apple-touch-icon" href="../../apple-touch-icon.png" sizes="180x180">
<link rel="icon" href="../../favicon-32x32.png" sizes="32x32">
<link rel="icon" href="../../favicon-16x16.png" sizes="16x16">
<link rel="icon" href="../../favicon.ico" sizes="48x48 32x32 16x16">
<link rel="manifest" href="../../site.webmanifest">
<link rel="mask-icon" href="../../safari-pinned-tab.svg" color="#1f91c2">
<meta name="msapplication-TileColor" content="#00aba9">
<meta name="theme-color" content="#cceeff">
<!-- favicons generated using http://realfavicongenerator.net/ --><!--[if lt IE 9]><script src="../../assets/js/html5shiv-printshiv.min.js"></script><![endif]--><meta name="author" content="Tanya Schlusser">
<link rel="next" href="../property-tax-cook-county/" title="Modeling property tax assessment in Cook County" type="text/html">
<meta property="og:site_name" content="Tanya Schlusser">
<meta property="og:title" content="MCMC and the Ising Model">
<meta property="og:url" content="https://tanyaschlusser.github.io/posts/mcmc-and-the-ising-model/">
<meta property="og:description" content="The Metropolis-Hastings method using both PyMC3 and standard techniques, demonstrated via the Ising model.">
<meta property="og:image" content="https://tanyaschlusser.github.io/posts/mcmc-and-the-ising-model/spins.png">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2018-07-29T00:00:42-05:00">
<meta property="article:tag" content="bayesian">
<meta property="article:tag" content="mcmc">
<meta property="article:tag" content="pymc3">
<meta name="twitter:card" content="summary">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0-beta/katex.min.css" integrity="sha256-sI/DdD47R/Sa54XZDNFjRWlS+Dv8MC5xfkqQLRh0Jes=" crossorigin="anonymous">
</head>
<body>
    <a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>
         
    <header id="header" class="hidden-print"><nav id="menu"><a href="https://tanyaschlusser.github.io/" title="Tanya Schlusser" rel="home">

        <svg viewbox="0 0 120 20" xmlns="http://www.w3.org/2000/svg"><desc>Tanya Schlusser</desc><text id="blog-title" y="15" transform="scale(1, 1.1)">Tanya Schlusser</text></svg></a>

    <ul>
<li><a href="../../projects/">Projects</a></li>
                <li><a href="../../slides/">Slides</a></li>
                <li><a href="../../archive.html">Archive</a></li>
    
    
    </ul></nav></header><main id="content"><article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><div class="metadata">
          <time datetime="2018-07-29T00:00:42-05:00" itemprop="datePublished">29 Jul 2018</time><span>Filed under </span><a href="../../categories/cat_methods">Methods</a>.
          

        </div>
        
    <h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">MCMC and the Ising Model</a></h1>

        

    </header><div class="e-content entry-content" itemprop="articleBody text">
    <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><span class="vocabulary" title="A sequence of statistical outcomes in which each step is statistically independent from all of the prior steps.">Markov-Chain</span>
<span class="vocabulary" title="A computer simulation technique using pseudo-random numbers to simulate random events.">Monte Carlo</span> (MCMC) methods are a category of numerical technique used in Bayesian statistics. They numerically estimate the distribution of a variable (the <span class="vocabulary" title="The prior times the likelihood,  normalized, is the posterior distribution: the probability distribution of the target variable after incorporating the observed data.">posterior</span>) given two other distributions: the <span class="vocabulary" title="A distribution that represents existing knowledge of a system. Often people choose a uniform (flat) distribution; or else something that is the known conjugate prior of a desired posterior distribution.">prior</span> and the <span class="vocabulary" title="A special name for the probability mass (or density) function when you fix the random variable (e.g. `x`) and integrate over the parameters (e.g. `mu` and `theta`). It's renamed 'likelihood' just to make that swap explicit when talking about it. The integral over the parameters may not equal one so you have to normalize.">likelihood function</span>, and are useful when direct integration of the likelihood function is not tractable.</p>
<p>I am new to Bayesian statistics, but became interested in the approach partly from exposure to the <a href=".">PyMC3 library</a>, and partly from FiveThirtyEight's promoting it in a <a href="https://fivethirtyeight.com/features/statisticians-found-one-thing-they-can-agree-on-its-time-to-stop-misusing-p-values/">commentary</a> soon after the time of the p-hacking scandals a few years back (<a href="https://www.ncbi.nlm.nih.gov/pubmed/22006061">Simmons et. al.</a> coin 'p-hacking' in 2011, and <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4359000">Head et. al.</a> quantify the scale of the issue in 2014).</p>
<p>Until the 1980's, it was not realistic to use Bayesian techniques except when analytic solutions were possible. (Here's Wikipedia's <a href="https://en.wikipedia.org/wiki/Conjugate_prior#Table_of_conjugate_distributions">list of analytic options</a>. They're still useful.) MCMC opens up more options.</p>
<p>The Python library <a href="https://docs.pymc.io/">pymc3</a> provides a suite of modern Bayesian tools: both MCMC algorithms and variational inference. One of its core contributors, Thomas Wiecki, wrote a blog post entitled <a href="https://twiecki.github.io/blog/2015/11/10/mcmc-sampling/">MCMC sampling for dummies</a>, which was the inspiration for this post. It was enthusiastically received, and cited by people I follow as the best available explanation of MCMC. To my dismay, I didn't understand it; probably because he comes from a stats background and I come from engineering. This post is for people like me.</p>
<!-- TEASER_END -->

<h4 id="MCMC-for-dumber-dummies-(i.e.-engineers-like-me)">MCMC for dumber dummies (i.e. engineers like me)<a class="anchor-link" href="#MCMC-for-dumber-dummies-(i.e.-engineers-like-me)">¶</a>
</h4>
<p>My first exposure to MCMC was via the Ising model. This post is for people like me who may remember the term "MCMC" from school and want to start from there to gain a working understanding of Bayesian numerical methods. If engineering concepts are familiar, this should be an accessible read.</p>
<p>If you have simulated the Ising model, you've already implemented the original MCMC algorithm: the Metropolis-Hastings Method. If not, the next section briefly describes both MCMC and the Ising model.</p>
<h3 id="Background">Background<a class="anchor-link" href="#Background">¶</a>
</h3>
<p>The Metropolis-Hastings method was first developed right after World War II, when Metropolis and his team were exploring the physics of fission and fusion for use in a thermonuclear weapon. They published the method, to be used in general statistical mechanics applications, in 1953. Teachers use the Ising model to teach the Metropolis-Hastings method because it's less complicated than modeling anything with moving atoms.</p>
<h4 id="Thermodynamic-ensembles-as-an-analogy-for-MCMC">Thermodynamic ensembles as an analogy for MCMC<a class="anchor-link" href="#Thermodynamic-ensembles-as-an-analogy-for-MCMC">¶</a>
</h4>
<p>Thermodynamic ensembles are a concept from engineering: Imagine any starting state we want in a system, and step it forward in time, allowing for randomness. If the system goes long enough, the randomness will even out and we can get an equilibrium value by averaging over the ensemble.</p>
<p>This example of mixing is how I visualize what's happening in Markov Chain Monte Carlo. Except instead of advancing in time, like here, the model advances a system through probability space toward more probable configurations.</p>
<canvas id="mcmc-ising-random-motion" width="250px" height="250px" style="display:block;margin:1em auto 0;">
    Even when the initial conditions are not random,
    like these two different colored balls balls placed
    in two separete corners of a box, the eventual long
    term average of the system looks like an even mixture.
</canvas>
</div>
</div>
</div>
<script>
//%%javascript
(function(){
    var canvas = document.getElementById("mcmc-ising-random-motion");
    var ctx = canvas.getContext('2d');
    var twoPI = Math.PI * 2;
    var i;
    canvas.setAttribute("role", "image");
    canvas.setAttribute("aria-label", canvas.innerHTML);
    ctx.clearRect(0, 0, canvas.width, canvas.height);
    
    const molecule = ({x=0, y=0, color="#dff", radius=10} = {}) => ({
      x, y, color, r: radius, x0: x, y0: y,
      xdot: Math.random() * 6,
      ydot: Math.random() * 6,
      handleCollision (other) {
        if (other === undefined) {  // Walls
            if (this.x < this.r) {
                this.x = this.r + this.r - this.x;
                this.xdot = -this.xdot;        
            } else if (this.x > ctx.canvas.width - this.r) {
                this.x = this.x - this.r;
                this.xdot = -this.xdot;
            }
            if (this.y < this.r) {
                this.y = this.r + this.r - this.y;
                this.ydot = -this.ydot;
            } else if (this.y > ctx.canvas.height - this.r) {
                this.y = this.y - this.r;
                this.ydot = -this.ydot;
            }
        } else {  // other molecule
            var dx = this.x - other.x;
            var dy = this.y - other.y;
            if (Math.pow(dx, 2) + Math.pow(dy, 2) < 4 * Math.pow(this.r, 2)) {
                // collision
                var xdenom = Math.abs(this.xdot) + Math.abs(other.xdot);
                var ydenom = Math.abs(this.ydot) + Math.abs(other.ydot);
                var tmp = other.xdot;
                other.xdot = this.xdot;
                this.xdot = tmp;
                tmp = other.ydot;
                other.ydot = this.ydot;
                this.ydot = tmp;
                this.x = this.x + dx/2 * Math.abs(this.xdot) / xdenom;
                this.y = this.y + dy/2 * Math.abs(this.ydot) / ydenom;
                other.x = other.x - dx/2 * Math.abs(other.xdot) / xdenom;
                other.y = other.y - dy/2 * Math.abs(other.ydot) / ydenom;
            }
        }
      },
      step() {
          this.x = this.x + this.xdot;
          this.y = this.y + this.ydot;
      },
      draw() {
        ctx.save();
        ctx.fillStyle = this.color;
        ctx.strokeStyle = 'black';
        ctx.beginPath();
        ctx.moveTo(this.x + this.r, this.y);
        ctx.arc(this.x, this.y, this.r, 0, twoPI, 0);
        ctx.fill();      
        ctx.stroke();
        ctx.closePath();
        ctx.restore();
      }
    });

    // Set up the molecules to draw
    var molecules = [];
    for (i=0; i<8; i++) {
        var col = (i < 4) ? "#fe3" : "#b00";
        var y0 = (i < 4) ? 10 : canvas.height - 10;
        molecules.push(molecule({x:(i+1)*10, y:y0, color:col}));
    }
    
    // Set up the animation function
    var counter = 0;
    function draw() {
        var i, j;
        for (i=0; i < molecules.length; i++) {
            if (counter < 10 | (counter > 1800 & counter < 1810)) {
                for (j=0; j < molecules.length; j++) {
                    molecules[j].x = molecules[j].x0;
                    molecules[j].y = molecules[j].y0;
                }
            } else {
                counter = (counter < 1810) ? counter : 0;
                molecules[i].step();            
            }
        }
        for (i=0; i < molecules.length; i++) {
            for (j=i+1; j < molecules.length; j++) {
                molecules[i].handleCollision(molecules[j]);
            }
            molecules[i].handleCollision(); // walls
        }
        ctx.beginPath();
        ctx.fillStyle = 'white';
        ctx.fillRect(0, 0, canvas.width, canvas.height);
        ctx.strokeRect(0, 0, canvas.width, canvas.height)
        ctx.closePath();
        ctx.lineWidth = 1;
        for (i=0; i < molecules.length; i++) {
            molecules[i].draw();
        }
        counter++;
    }

  // Animate
  window.setInterval(draw, 20);
})(); </script><div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Ising-model">Ising model<a class="anchor-link" href="#Ising-model">¶</a>
</h4>
<p>The Ising model is named for Ernst Ising, a student of Wilhelm Lenz. He solved the 1-D problem for his doctoral thesis in 1920. In the model, a material is represented by a regular lattice of atoms that can have positive or negative dipole moment (magnetic spin $s$ is up or down: $s = \pm 1$).</p>
<p>For two or more dimensions, there is a Curie temperature $T_c$ at which a phase transition occurs. Below $T_c$, the substance behaves as if it were magnetic. Above it, thermal energy disrupts the tendency toward alignment, and the substance acts as a paramagnetic one.</p>
<p>Here is an example drawing of a typical state below the critical temperature (left—all one spin—100% magnetization) and above the critical temperature (right—random spins—nearly 0% magnetization):</p>
<canvas id="mcmc-ising-two-lattices" width="600px" height="250px" style="display:block;margin:1em auto 0;">
    Two 2-D lattices. One is all white, showing spins aligned. The other is randomly half blue and half white, showing spins not aligned.
</canvas><h5 id="Boltzmann-distribution:-where-the-MCMC-comes-in">Boltzmann distribution: where the MCMC comes in<a class="anchor-link" href="#Boltzmann-distribution:-where-the-MCMC-comes-in">¶</a>
</h5>
<p>In the Ising model, the distribution of spins in the lattice depends on temperature, and follows the Boltzmann distribution:</p>
<p>$$
    \text{frequency distribution} \propto e^{-E / k T}
$$</p>
<p>In which $k$ is Boltzmann's constant, $T$ is the lattice temperature, and $E$ is the total energy from magnetization. When there is no external magnetic field, and given a coupling parameter $J &gt; 0$ (a property of the particular material), the energy from magnetization is:</p>
<p>$$
   E = - J \sum_{\text{(atoms)}}\sum_{\text{(neighbor atoms)}}
       \left( s_{\text{atom}} \cdot s_{\text{neighbor}}\right)
$$</p>
<p>There's a shorthand notation:</p>
<p>$$
   E =  - J \sum_{&lt;i, j&gt;} s_i s_j
$$</p>
<p>The subscript $&lt;i, j&gt;$ denotes a sum over each atom's $j$ nearest neighbors.</p>
<p>The goal of the model is to identify  $T_c$. We do that by running the MCMC analysis a bunch of times at different temperatures to determine the average magnetization as a function of temperature. Then it's pretty clear where the discontinuity occurs.</p>
<p>The solution in this post is from a <a href="http://farside.ph.utexas.edu/teaching/329/lectures/node110.html">lecture by Richard Fitzpatrick</a> at the University of Texas. His lecture is understandable and thorough.</p>

</div>
</div>
</div>
<script>
// %%javascript
(function(){
    var canvas = document.getElementById("mcmc-ising-two-lattices");
    var ctx = canvas.getContext('2d');
    var i, j, r=10, g=25, dx=canvas.width-g*10;
    var twoPI = Math.PI * 2;
    canvas.setAttribute("role", "image");
    canvas.setAttribute("aria-label", canvas.innerHTML);
    ctx.clearRect(0, 0, canvas.width, canvas.height);
    ctx.strokeStyle = "black";
    ctx.fillStyle = "#fff";
    ctx.font = "12px sans-serif";
    ctx.textAlign = "center";
    // grid
    for (i=0; i <= 10; i++) {
        ctx.beginPath();
        ctx.moveTo(i*g,0); ctx.lineTo(i*g, g*10);
        ctx.moveTo(0, i*g); ctx.lineTo(canvas.height, i*g);
        ctx.moveTo(dx+i*g,0); ctx.lineTo(dx+i*g, canvas.height);
        ctx.moveTo(dx, i*g); ctx.lineTo(canvas.width, i*g);
        ctx.closePath();
        ctx.stroke();
    }
    // molecules
    for (i=0; i <= 10; i++) {
        for (j=0; j<= 10; j++) {
            // magnetized
            ctx.beginPath();
            ctx.arc(i*g, j*g, r, 0, twoPI);
            ctx.stroke();
            ctx.fill();
            ctx.fillStyle = "#000";
            ctx.fillText("↑", i*g, j*g + r/2);
            ctx.fillStyle = "#fff";
            // not magnetized
            ctx.beginPath();
            ctx.arc(dx + i*g, j*g, r, 0, twoPI);
            ctx.stroke();
            if (Math.random() < .5) {
                ctx.fillStyle = "#33d";
                ctx.fill(); 
                ctx.fillStyle = "#ccc";
                ctx.fillText("↓", dx + i*g, j*g + r/2);
                ctx.fillStyle = "#fff";
            } else {
                ctx.fill();
                ctx.fillStyle = "#000";
                ctx.fillText("↑", dx + i*g, j*g + r/2);
                ctx.fillStyle = "#fff";
            }
        }
    }
})();</script><div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Options">Options<a class="anchor-link" href="#Options">¶</a>
</h3>
<p>Here are three approaches to calculating the equilibrium magnetization:</p>
<h4 id="Sum-over-all-states">Sum over all states<a class="anchor-link" href="#Sum-over-all-states">¶</a>
</h4>
<p>We can brute-force calculate the equilibrium magnetization of the
system by iterating through every single possible state, calculating
its energy given the magnetization, and then performing a weighted average based on its frequency, $\exp(-E / k T)$:</p>
<p>$$
\begin{aligned}
\text{average magnetization} &amp;= \sum_{\text{all configurations}}
          \text{magnetization} \cdot \text{frequency of configuration} \\
          &amp;= \sum_{\text{all configurations}}
          \text{magnetization} \cdot e^{-E / k T}
\end{aligned}
$$</p>
<p>But that's a lot of states. Even if we have a quite small $10 \times 10$ grid, it makes 100 positions and thus—with spin up and spin down—$2^{100}$ total different configurations. At modern processor speeds, this is still a time prohibitive approach.</p>
<h4 id="Weighted-sum-over-randomly-chosen-states">Weighted sum over randomly-chosen states<a class="anchor-link" href="#Weighted-sum-over-randomly-chosen-states">¶</a>
</h4>
<p>So, rather than stepping through all of the possible configurations, what if we randomly choose a bunch of configurations and take the weighted average of their frequency?</p>
<p>The problem is it's inefficient. The Boltzmann distribution is not uniform: it is weighted toward lower energies. Ideally, we'd find some way to pick spin configurations that correspond more often to the more frequently occurring states.</p>
<canvas id="mcmc-ising-Boltzmann-distribution" width="350px" height="250px" style="display:block;margin:1em auto 0;">
    Plot of a section of the Boltzmann distribution near zero: the point is to show that, since it's a decreasing exponential function, the bulk of the distribution is concentrated near zero.
</canvas><h4 id="Metropolis-Hastings-method">Metropolis-Hastings method<a class="anchor-link" href="#Metropolis-Hastings-method">¶</a>
</h4>
<p>And that's precisely the contribution from nuclear physicist Nicholas Metropolis and his team of mathematicians <a href="https://aip.scitation.org/doi/10.1063/1.1699114">(Metropolis paper, paywalled)</a>. The method was originally published in 1953. They pioneered both the use of random-number generation for simulation (Monte Carlo methods) and the chaining of random steps (Markov Chain Monte Carlo) in their work for the Manhattan project.</p>
<p>They use their newly created technique to take a random walk through the configuration space, visiting the more frequently-occurring spin configurations more often, and drastically speeding up the calculation. In their words:</p>
<blockquote>
 Instead of choosing configurations randomly,
 then weighting them with $\exp(-E/kT)$, we choose
 configurations with a probability $\exp(-E/kT)$ and
 weight them evenly.
</blockquote>
<p>They never really explained the statistics behind why it worked, though. Just the physics of what was happening. That's why it's named Metropolis-Hastings: the '-Hastings' acknowledges the statistician W. K. Hastings's contribution in 1970, when the theory behind the technique was finally explained and generalized <a href="https://www.jstor.org/stable/2334940">(Hastings paper)</a>.</p>
<p>I'm not a physicist or a statistician, so it's a testament to the writing talent of both Hastings and the Metropolis team that their papers are actually understandable to people with an average engineering background and a bit of stats. Hastings writes:</p>
<blockquote>
The main features of these methods for sampling from a
distribution with density $p(x)$ are:
    <ol>
<li type="a">
     The computations depend on $p(x)$ only through ratios
     of the form $p(x')/p(x)$, where $x'$ and $x$ are sample
     points. Thus, the normalizing constant need not be known,
     no factorization of $p(x)$ is necessary, and the methods
     are very easily implemented on a computer. [...]
  </li>
<li type="a">
      A sequence of samples is obtained by simulating a
      Markov chain. The resulting samples are therefore
      correlated and estimation of the standard deviation
      of an estimate and assessment of the error of an
      estimate may require more care than with
      independent samples. 
    </li>
</ol>
</blockquote>
</div>
</div>
</div>
<script>
// %%javascript
(function(){
    var canvas = document.getElementById("mcmc-ising-Boltzmann-distribution");
    var ctx = canvas.getContext('2d');
    canvas.setAttribute("role", "image");
    canvas.setAttribute("aria-label", canvas.innerHTML);
    ctx.clearRect(0, 0, canvas.width, canvas.height);

    function makeMapping(domain, range) {
        function mapping(input) {
            return range[0] + (range[1] - range[0]) * input / (domain[1] - domain[0]);
        }
        return mapping;
    }
    var x = makeMapping([0, 5], [15, canvas.width-10]);
    var y = makeMapping([0, 1], [canvas.height-15, 10]);
    
    // Axes
    ctx.strokeStyle = "black";
    ctx.lineWidth = 1;
    ctx.beginPath();
    ctx.moveTo(x(0), y(1));
    ctx.lineTo(x(0), y(0));
    ctx.lineTo(x(5), y(0));
    ctx.stroke();
    // Curve
    ctx.strokeStyle = "#58f";
    ctx.lineWidth = 3;
    ctx.beginPath();
    var prev = [x(.01), y(Math.exp(-0.01))];
    ctx.moveTo(prev[0], prev[1]);
    for (var i=2; i<100; i++) {
        var e_kT = i/20;
        var fDist = Math.exp(-i/20);
        var next = [x(e_kT), y(fDist)];
        var mid = [(prev[0]+next[0])/2, (prev[1]+next[1])/2];
        ctx.bezierCurveTo(mid[0], mid[1], mid[0], mid[1], next[0], next[1]);
        prev = next;
    }
    ctx.stroke()
    // Annotation
    ctx.font = "14px sans-serif";
    ctx.fillStyle = "#000";
    ctx.fillText("lower energy:", x(.18), y(.93));
    ctx.fillText("more often", x(.21), y(.86));
    ctx.fillText("higher energy:", x(3.69), y(.13));
    ctx.fillText("less often", x(3.72), y(.06));
    ctx.stroke();
})();</script><div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="What-Hastings-was-saying">What Hastings was saying<a class="anchor-link" href="#What-Hastings-was-saying">¶</a>
</h5>
<p>It's easier to understand ideas with a concrete example like the Ising model. The important physics, described earlier, is that the spin configurations follow the Boltzmann distribution:</p>
<p>$$
 \text{frequency distribution of configurations} \propto \exp(-E / k T)
$$</p>
<p>This notation is too verbose, so let:</p>
<ul>
<li>$x$ = the configuration of the lattice</li>
<li>$p$ = the frequency distribution of the configurations (the probability mass function)</li>
<li>$\tilde{T}$ = dimensionless temperature $\tilde{T} = k T / J$</li>
<li>$H(x)$ = the sum over neighboring spins $\sum_{&lt;ij&gt;} s_i s_j$ for configuration $x$</li>
</ul>
<p>With the new symbols:</p>
<p>$$
 p(x) \propto \exp(-H(x)/\tilde{T})
      = \exp\biggl(-\frac{1}{\tilde{T}}  \sum_{&lt;ij&gt;} s_i s_j \biggr)
$$</p>
<p>The reason we just say it's proportional to is because in order to know
the probability that a specific spin configuration occurs, you need to divide it by all of the possible configurations so that the probabilities add up to one:</p>
<p>$$
 p(x) =
  \frac{ \exp(- H(x) / \tilde{T}) }
  { \sum_{\text{all }x} \exp(- H(x) / \tilde{T}) }
$$</p>
<p>But we don't know the denominator. Which was the original hangup for Bayesian statisticians. Fortunately, it's not a problem when you use MCMC. Like Hastings said,</p>
<blockquote>
The computations depend on $p(x)$ only through ratios
     of the form $p(x')/p(x)$,<wbr> where $x'$ and $x$ are sample
     points. Thus, the normalizing constant need not be known,
     no factorization of $p(x)$ is necessary, and the methods
     are very easily implemented on a computer. 
</wbr>
</blockquote>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Implementation">Implementation<a class="anchor-link" href="#Implementation">¶</a>
</h3>
<p>For the Ising model, the Metropolis-Hasting algorithm follows these steps:</p>
<ol>
<li>Pick a starting spin configuration $x$.</li>
<li>Pick a new spin configuration $x'$.</li>
<li>Make a random choice to take the new configuration or keep
the old one, weighted by the relative likelihoods of the
new configuration vs. the old one  $p(x')/p(x)$.</li>
<li>Repeat #2 to #3 until the system converges.</li>
<li>Except actually this one just goes $N$ steps instead of checking for convergence because all I want to do is make an animation of the transient part.</li>
</ol>
<p>The probability mass function for $x$ is</p>
<p>$$
 p(x) =
  \frac{ \exp(- H(x) / \tilde{T}) }
  { \sum_{\text{all }x} \exp(- H(x) / \tilde{T}) }
$$</p>
<p>which means that for step #3, the ratio of likelihoods is</p>
<p>$$
 \frac{p(x')}{p(x)} =
  \frac{ \exp(- H(x') / \tilde{T}) }
       { \sum_{\text{all }x} \exp(- H(x) / \tilde{T}) } \bigg/
  \frac{ \exp(- H(x) / \tilde{T}) }
       { \sum_{\text{all }x} \exp(- H(x) / \tilde{T}) }
$$</p>
<p>It's a ratio, so we can cancel out the sum over all configurations</p>
<p>$$
 \frac{p(x')}{p(x)} =
 \frac{ \exp(- H(x') / \tilde{T}) }
      { \exp(- H(x) / \tilde{T})  }
$$</p>
<p>Rearranging, the ratio of likelihoods is:</p>
<p>$$
 \frac{p(x')}{p(x)} =
 \exp\left(- \frac{H(x') - H(x)}{\tilde{T}}\right)
$$</p>
<p>And now so long as the algorithm selects the
new configuration $x'$ relative to the old configuration $x$
with the above proportion, we will walk the Markov Chain with
appropriate weighted probabilities.
Hastings describes a couple of options in the literature,
but says the choice by Metropolis and his team was the most efficient.
So, the algorithm is to switch to $x'$ from $x$ with the probability:</p>
<p>$$
p(\text{switch to }x') = \left\lbrace
\begin{matrix}
1 &amp; \text{ if }  H(x') - H(x) &lt; 0
  \kern1em\text{(lower energy)}\\
\exp\left(- \frac{H(x') - H(x)}{\tilde{T}}\right) &amp; \text{ if }  H(x') - H(x) \ge 0
  \kern1em\text{(higher energy)}  
\end{matrix}
\right.
$$</p>
<h4 id="Setup">Setup<a class="anchor-link" href="#Setup">¶</a>
</h4>
<p>The code uses these Python libraries:</p>
<div class="highlight"><pre><span></span>numpy mkl-service theano pymc3 array2gif
</pre></div>
<p>This first chunk of code has nothing to do with MCMC. It's for visualization: it converts an array of spin lattices (spin values $\pm 1$) to blue and white and writes it to an animated gif.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">array2gif</span> <span class="k">import</span> <span class="n">write_gif</span>


<span class="k">def</span> <span class="nf">to_two_color</span><span class="p">(</span><span class="n">lattice</span><span class="p">):</span>
    <span class="n">blue</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">lattice</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)</span> <span class="o">*</span> <span class="mi">255</span> 
    <span class="n">red</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">lattice</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)</span>
    <span class="n">red</span><span class="p">[</span><span class="n">lattice</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">255</span> 
    <span class="n">green</span> <span class="o">=</span> <span class="n">red</span> 
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">red</span><span class="p">,</span> <span class="n">green</span><span class="p">,</span> <span class="n">blue</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">output_to_gif</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">filename</span><span class="p">,</span> <span class="n">fps</span><span class="o">=</span><span class="mi">8</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Frames: </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)))</span>
    <span class="n">colors</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">write_gif</span><span class="p">(</span>
        <span class="p">[</span><span class="n">to_two_color</span><span class="p">(</span><span class="n">lattice</span><span class="p">)</span> <span class="k">for</span> <span class="n">lattice</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">],</span>
        <span class="n">filename</span><span class="p">,</span>
        <span class="n">fps</span><span class="o">=</span><span class="n">fps</span>
    <span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Standard-approach">Standard approach<a class="anchor-link" href="#Standard-approach">¶</a>
</h4>
<p>The code in this section implements the Metropolis-Hastings method for the Ising model as
<a href="http://farside.ph.utexas.edu/teaching/329/lectures/node110.html">Richard Fitzpatrick describes it</a>.
The code about to calculate the energy (<code>get_dH</code>) appears first. After that,
in <code>standard_approach</code>, comes the MCMC implementation.</p>
<p>The function <code>get_dH</code> calculates $H(x') - H(x)$.
Because none of the other positions in the lattice change,
it is not necessary to calculate the energy except at the
location $i,j$ of the flip.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_dH</span><span class="p">(</span><span class="n">lattice</span><span class="p">,</span> <span class="n">trial_location</span><span class="p">):</span>
    <span class="sd">""" H = - Sum_&lt;ij&gt;(s_i s_j) """</span>
    <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="o">=</span> <span class="n">trial_location</span>
    <span class="n">height</span><span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="n">lattice</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">H</span><span class="p">,</span> <span class="n">Hflip</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">di</span><span class="p">,</span> <span class="n">dj</span> <span class="ow">in</span> <span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)):</span>
        <span class="n">ii</span> <span class="o">=</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="n">di</span><span class="p">)</span> <span class="o">%</span> <span class="n">height</span>
        <span class="n">jj</span> <span class="o">=</span> <span class="p">(</span><span class="n">j</span> <span class="o">+</span> <span class="n">dj</span><span class="p">)</span> <span class="o">%</span> <span class="n">width</span>
        <span class="n">H</span> <span class="o">-=</span> <span class="n">lattice</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="n">jj</span><span class="p">]</span> <span class="o">*</span> <span class="n">lattice</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
        <span class="n">Hflip</span> <span class="o">+=</span> <span class="n">lattice</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="n">jj</span><span class="p">]</span> <span class="o">*</span> <span class="n">lattice</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">Hflip</span> <span class="o">-</span> <span class="n">H</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The function <code>standard_approach</code> creates a lattice with values
$\pm 1$, and loops through all positions $N * 5$ times, taking
a snapshot every 5<sup>th</sup> step.</p>
<p>It's not very random to step through every position in the
lattice sequentially...but it's faster than randomly
selecting positions because you are certain to visit every position in the fewest possible steps.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">standard_approach</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">N</span><span class="o">=</span><span class="mi">60</span><span class="p">):</span>
    <span class="c1"># Randomly initialize the spins to either +1 or -1</span>
    <span class="n">lattice</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">))</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">snapshots</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">snapshot</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">snapshots</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">to_two_color</span><span class="p">(</span><span class="n">lattice</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="si">{:2.0%}</span><span class="s1"> complete. Net magnetization: </span><span class="si">{:3.0%}</span><span class="s1">'</span>
              <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">snapshot</span> <span class="o">/</span> <span class="n">N</span><span class="p">,</span>
                      <span class="nb">abs</span><span class="p">(</span><span class="n">lattice</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span> <span class="o">/</span> <span class="n">lattice</span><span class="o">.</span><span class="n">size</span><span class="p">),</span>
              <span class="n">end</span><span class="o">=</span><span class="s1">'</span><span class="se">\r</span><span class="s1">'</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
            <span class="c1"># Walk through the array flipping atoms.</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">height</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">width</span><span class="p">):</span>
                    <span class="n">dH</span> <span class="o">=</span> <span class="n">get_dH</span><span class="p">(</span><span class="n">lattice</span><span class="p">,</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">))</span>
                    <span class="k">if</span> <span class="n">dH</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># lower energy: flip for sure</span>
                        <span class="n">lattice</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">lattice</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
                    <span class="k">else</span><span class="p">:</span>  <span class="c1"># Higher energy: flip sometimes</span>
                        <span class="n">probability</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">dH</span> <span class="o">/</span> <span class="n">T</span><span class="p">)</span>
                        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">probability</span><span class="p">:</span>
                            <span class="n">lattice</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">lattice</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">snapshots</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Using-PyMC3">Using PyMC3<a class="anchor-link" href="#Using-PyMC3">¶</a>
</h4>
<p>The code in this section implements the Metropolis-Hastings method for the Ising model using PyMC3.</p>
<p>The function <code>get_H</code> calculates the full $H(x)$ for the lattice, because in the PyMC3
implementation, each step is actually completely independent of the next (it's supposed to be),
meaning I can't access the prior state's lattice configuration to calculate the difference
<code>get_dH</code>, $H(x') - H(x)$, like in the custom code.</p>
<p>The lattice in this case is a Bernoulli random variable, so its
values are $\lbrace 0, 1\rbrace$ not $\lbrace -1, +1\rbrace$.
That's the reason for the <code>to_spins</code> function, which converts
to $\lbrace -1, +1\rbrace$. Then <code>get_H</code> uses Theano for GPU
matrix math (when available); in this case to shift the matrix indices
by one to get the nearest neighbors.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">theano</span>
<span class="kn">import</span> <span class="nn">theano.tensor</span> <span class="k">as</span> <span class="nn">tt</span>
<span class="kn">import</span> <span class="nn">pymc3</span> <span class="k">as</span> <span class="nn">pm</span>
<span class="kn">from</span> <span class="nn">theano.compile.ops</span> <span class="k">import</span> <span class="n">as_op</span>

<span class="c1"># Fix compile failure on OSX</span>
<span class="c1"># https://stackoverflow.com/a/51312739</span>
<span class="n">theano</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">gcc</span><span class="o">.</span><span class="n">cxxflags</span> <span class="o">=</span> <span class="s2">"-Wno-c++11-narrowing"</span>


<span class="k">def</span> <span class="nf">get_H</span><span class="p">(</span><span class="n">spins</span><span class="p">):</span>
    <span class="n">H</span> <span class="o">=</span> <span class="o">-</span> <span class="p">(</span>
        <span class="n">tt</span><span class="o">.</span><span class="n">roll</span><span class="p">(</span><span class="n">spins</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">spins</span> <span class="o">+</span>
        <span class="n">tt</span><span class="o">.</span><span class="n">roll</span><span class="p">(</span><span class="n">spins</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="n">spins</span> <span class="o">+</span>
        <span class="n">tt</span><span class="o">.</span><span class="n">roll</span><span class="p">(</span><span class="n">spins</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">spins</span> <span class="o">+</span>
        <span class="n">tt</span><span class="o">.</span><span class="n">roll</span><span class="p">(</span><span class="n">spins</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="n">spins</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">H</span>


<span class="k">def</span> <span class="nf">to_spins</span><span class="p">(</span><span class="n">lattice</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">lattice</span> <span class="o">-</span> <span class="mi">1</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The way PyMC3 is used here is nonstandard: typically you'd use observed values to update the <span class="vocabulary" title="The prior is a probability distribution that reflects all of the previous knowledge of the system to this point. Often the uniform (flat) distribution, which implies no previous knowledge.">prior</span> estimate of the variables you're looking for, but this example has no observed values. Instead, it adds the <code>pm.Potential</code>, which will change the <span class="vocabulary" title="Likelihood is what statisticians rename the probability mass function (or density function) when you fix the the observed value (usually the `x`) and instead vary distribution parameters (such as `theta`). In equation form, instead of p(x|theta) they write it L(theta) = p(theta|x).">likelihood</span> directly to guide the MCMC random walk toward the lower-energy configurations.</p>
<p>The function <code>mc3_approach</code> runs the MCMC simulation using PyMC3. It performs th same function as <code>standard_approach</code>, for the most part. The main difference is it uses a full-blown MCMC framework, so we can't cheat and step through the positions in sequence like we did with the custom code.</p>
<p>Instead, at each step it will draw an entirely new lattice to try. The problem with this is multiple spins may cancel each other out, meaning the MCMC algorithm will take longer to converge. To fix this, we set <code>scaling = .0006</code> so that on average only one position in the lattice will change at each step. (From the source code, a random uniform value must be below   <code>1 - .5**scaling</code> for the algorithm to attempt a flip.)</p>
<p>Here's the function. Each line will be broken down in the next section.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">mc3_approach</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">N</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">)</span>
    <span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="s1">'x'</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">testval</span><span class="o">=</span><span class="n">x0</span><span class="p">)</span>
        <span class="n">magnetization</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Potential</span><span class="p">(</span>
            <span class="s1">'m'</span><span class="p">,</span>
            <span class="o">-</span><span class="n">get_H</span><span class="p">(</span><span class="n">to_spins</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">/</span> <span class="n">T</span>
        <span class="p">)</span>
        <span class="n">scaling</span> <span class="o">=</span> <span class="o">.</span><span class="mi">0006</span>
        <span class="n">mul</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">height</span> <span class="o">*</span> <span class="n">width</span> <span class="o">*</span> <span class="mf">1.75</span><span class="p">)</span>
        <span class="n">step</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">BinaryMetropolis</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">scaling</span><span class="o">=</span><span class="n">scaling</span><span class="p">)</span>
        <span class="n">trace</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">N</span> <span class="o">*</span> <span class="n">mul</span> <span class="o">*</span> <span class="mi">5</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">step</span><span class="p">,</span> <span class="n">chains</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">tune</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="p">[</span><span class="n">to_two_color</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">t</span><span class="p">[</span><span class="s1">'x'</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">trace</span><span class="p">[::</span><span class="n">mul</span> <span class="o">*</span> <span class="mi">5</span><span class="p">]]</span>
    <span class="c1"># Print out the final percent magnetization</span>
    <span class="n">lattice</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">trace</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="s1">'x'</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'Finished. Net magnetization: </span><span class="si">{:3.0%}</span><span class="s1">'</span>
              <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">lattice</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span> <span class="o">/</span> <span class="n">lattice</span><span class="o">.</span><span class="n">size</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">dataset</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The middle part is where the PyMC3 library is used. The code below is the same as above starting from the PyMC3 model context (<code>with pm.Model() as model</code>), with added comments.</p>
<div class="highlight"><pre><span></span><span class="c1"># PyMC3 uses a model context to collect all of the</span>
<span class="c1"># random variables together. Every random variable that</span>
<span class="c1"># is declared inside this context will be attached to</span>
<span class="c1"># the model. The variables can depend on each other,</span>
<span class="c1"># and will advance through the Markov Chain together.</span>

<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model</span><span class="p">:</span>
    <span class="c1"># PyMC3 has pre-defined common discrete and continuous</span>
    <span class="c1"># distributions. The Bernoulli distribution has values</span>
    <span class="c1"># that are in {0, 1}.</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="s1">'x'</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">testval</span><span class="o">=</span><span class="n">x0</span><span class="p">)</span>

    <span class="c1"># The Potential function is summed and added to the</span>
    <span class="c1"># overall log-likelihood. PyMC3 uses log-likelihood</span>
    <span class="c1"># instead of likelihood so when they take p(x')/p(x)</span>
    <span class="c1"># they can do it with subtraction:</span>
    <span class="c1">#   log( p(x') / p(x)) = log(p(x')) - log(p(x))</span>
    <span class="c1">#</span>
    <span class="c1"># So, long story--this line plays the same role as</span>
    <span class="c1"># the `get_dH` function earlier.</span>
    <span class="n">magnetization</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Potential</span><span class="p">(</span><span class="s1">'m'</span><span class="p">,</span> <span class="o">-</span><span class="n">get_H</span><span class="p">(</span><span class="n">to_spins</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="o">/</span> <span class="n">T</span><span class="p">)</span>

    <span class="c1"># `scaling` limits the fraction of positions in `x`</span>
    <span class="c1"># that flip at every step in the Markov Chain.</span>
    <span class="c1"># From the PyMC3 source:</span>
    <span class="c1">#     p_jump = 1. - .5 ** self.scaling</span>
    <span class="c1">#     ...</span>
    <span class="c1">#     switch_locs = (rand_array &lt; p_jump)</span>
    <span class="n">scaling</span> <span class="o">=</span> <span class="o">.</span><span class="mo">0006</span>

    <span class="c1"># `mul` was originally height * width to make the same</span>
    <span class="c1"># number of iterations as in the standard approach.</span>
    <span class="c1"># I made it bigger because the trace didn't converge.</span>
    <span class="n">mul</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">height</span> <span class="o">*</span> <span class="n">width</span> <span class="o">*</span> <span class="mf">1.75</span><span class="p">)</span>

    <span class="c1"># PyMC3 has a lot of different step options, including</span>
    <span class="c1"># No U-Turn sampling (NUTS), slice, and Hamiltonian</span>
    <span class="c1"># Monte-Carlo. The Metropolis method is the oldest;</span>
    <span class="c1"># the others may converge faster depending on the</span>
    <span class="c1"># application.</span>
    <span class="n">step</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">BinaryMetropolis</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">scaling</span><span class="o">=</span><span class="n">scaling</span><span class="p">)</span>

    <span class="c1"># `trace` is the object that contains all of the steps.</span>
    <span class="c1"># When there are multiple random variables in the model,</span>
    <span class="c1"># it will contain all of those variables.</span>
    <span class="n">trace</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">N</span> <span class="o">*</span> <span class="n">mul</span> <span class="o">*</span> <span class="mi">5</span><span class="p">,</span>
                      <span class="n">step</span><span class="o">=</span><span class="n">step</span><span class="p">,</span>
                      <span class="n">chains</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>  <span class="c1"># default is 2</span>
                      <span class="n">tune</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
<h4 id="Now-run-both-approaches">Now run both approaches<a class="anchor-link" href="#Now-run-both-approaches">¶</a>
</h4>
<p>Finally, this is the part where the two different methods are called
and compared. I had to increase the number of samples in the MC3 approach
because the random choices weren't as efficient as stepping through the
lattice. Also, I chose numbers far above and below the critical ratio
so that the test runs would converge faster with this larger matrix size.</p>
<p>You would normally run this on a 10x10 or maybe 20x20 lattice, and run for many more steps to get better convergence, but blog posts need visuals, and I wanted an animation of the transient state. I couldn't make the lattice bigger because I was running into memory issues for the PyMC3 method (which stores every single value in the <code>trace</code>).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="n">T_over_Tc</span><span class="o">=.</span><span class="mi">9</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">mc3</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">Tc</span> <span class="o">=</span> <span class="mf">2.269</span>  <span class="c1"># Normalized T := kT/J</span>
    <span class="n">T</span> <span class="o">=</span> <span class="n">T_over_Tc</span> <span class="o">*</span> <span class="n">Tc</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">mc3</span><span class="p">:</span>
       <span class="n">dataset</span> <span class="o">=</span> <span class="n">mc3_approach</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">N</span><span class="o">=</span><span class="mi">80</span><span class="p">)</span>
       <span class="n">filename</span> <span class="o">=</span> <span class="p">(</span><span class="s1">'mc3_ising_</span><span class="si">{}</span><span class="s1">_</span><span class="si">{}</span><span class="s1">x</span><span class="si">{}</span><span class="s1">.gif'</span>
                   <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">T_over_Tc</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
       <span class="n">dataset</span> <span class="o">=</span> <span class="n">standard_approach</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">N</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>
       <span class="n">filename</span> <span class="o">=</span> <span class="p">(</span><span class="s1">'ising_</span><span class="si">{}</span><span class="s1">_</span><span class="si">{}</span><span class="s1">x</span><span class="si">{}</span><span class="s1">.gif'</span>
                   <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">T_over_Tc</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">))</span>
    <span class="n">write_gif</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">filename</span><span class="p">,</span> <span class="n">fps</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

<span class="n">run</span><span class="p">(</span><span class="n">T_over_Tc</span><span class="o">=.</span><span class="mi">75</span><span class="p">)</span>
<span class="n">run</span><span class="p">(</span><span class="n">T_over_Tc</span><span class="o">=.</span><span class="mi">75</span><span class="p">,</span> <span class="n">mc3</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">run</span><span class="p">(</span><span class="n">T_over_Tc</span><span class="o">=</span><span class="mf">1.25</span><span class="p">)</span>
<span class="n">run</span><span class="p">(</span><span class="n">T_over_Tc</span><span class="o">=</span><span class="mf">1.25</span><span class="p">,</span> <span class="n">mc3</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>98% complete. Net magnetization:  97%
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>Sequential sampling (1 chains in 1 job)
BinaryMetropolis: [x]
100%|██████████| 1750000/1750000 [24:57&lt;00:00, 1168.24it/s]
Only one chain was sampled, this makes it impossible to run some convergence checks
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Finished. Net magnetization: 100%
98% complete. Net magnetization:   2%
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>Sequential sampling (1 chains in 1 job)
BinaryMetropolis: [x]
100%|██████████| 1750000/1750000 [21:42&lt;00:00, 1343.42it/s]
Only one chain was sampled, this makes it impossible to run some convergence checks
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Finished. Net magnetization:   0%
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Result">Result<a class="anchor-link" href="#Result">¶</a>
</h4>
<p>Convergence is faster with the custom code because the 'random walk' was actually stepping through each lattice position in sequence. Still, it's possible to see the system settling in to magnetization for $T = 0.75 T_c$ in both implementations. And even though in the PyMC3 implementation, the higher temperature system looks a lot less active than in the custom implementation, the net magnetization in both is near zero, with equal amounts of spin up and down.</p>
<div style="display:flex;justify-content:space-around;">
    <figure style="margin:1em"><figcaption>Standard method<br>$T = 0.75 T_c$</figcaption><img src="ising_0.75_50x50.gif" style="width:100px;height:100px"></figure><figure style="margin:1em"><figcaption>Standard method<br>$T = 1.25 T_c$</figcaption><img src="ising_1.25_50x50.gif" style="width:100px;height:100px"></figure><figure style="margin:1em"><figcaption>pymc3 method:<br>$T = 0.75 T_c$</figcaption><img src="mc3_ising_0.75_50x50.gif" style="width:100px;height:100px"></figure><figure style="margin:1em"><figcaption>pymc3 method:<br>$T = 1.25 T_c$</figcaption><img src="mc3_ising_1.25_50x50.gif" style="width:100px;height:100px"></figure>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Conclusion">Conclusion<a class="anchor-link" href="#Conclusion">¶</a>
</h3>
<p>The PyMC3 library provides a ready-made framework for applying Markov Chain Monte Carlo methods in Bayesian inference.</p>
<ul>
<li>If you're an engineer, it's not bad to think of MCMC as a generalized
method for creating "thermodynamic ensembles" of any real-world variable.</li>
<li>The system steps through probability space, with a weighted random
walk that's biased toward the more likely states.</li>
<li>At the end, you will have a sample trace that contains the
samples from the random walk. The weighting of the walk is such that
if you randomly draw new predictions from the tail end of the trace
(after it has converged), your draws will follow the posterior
distribution of your target variable.</li>
<li>It uses Theano under the hood. Theano is a matrix math library that can leverage the NVIDIA
GPU. The caveat is that custom code requires using Theano's functions for
<a href="http://deeplearning.net/software/theano/library/tensor/basic.html">tensor math</a>.
Note that <a href="https://github.com/pymc-devs/pymc4">PyMC4</a>
is about to come out and it depends on TensorFlow if you prefer that
to Theano.</li>
</ul>
<p>PyMC3 also implements No U-Turn Sampling (NUTS) and Hamiltonian Monte Carlo methods. They are modern MCMC techniques that speed up convergence in some cases by using different weights on the random walk.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">sys</span><span class="o">,</span> <span class="nn">platform</span><span class="o">,</span> <span class="nn">IPython</span><span class="o">,</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span><span class="o">,</span> <span class="nn">mkl</span><span class="o">,</span> <span class="nn">theano</span><span class="o">,</span> <span class="nn">pymc3</span> <span class="k">as</span> <span class="nn">pm</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"This notebook was created on an </span><span class="si">%s</span><span class="s2"> computer running OSX </span><span class="si">%s</span><span class="s2"> and using:</span><span class="se">\n</span><span class="s2">Python </span><span class="si">%s</span><span class="se">\n</span><span class="s2">IPython </span><span class="si">%s</span><span class="se">\n</span><span class="s2">mkl </span><span class="si">%s</span><span class="se">\n</span><span class="s2">NumPy </span><span class="si">%s</span><span class="se">\n</span><span class="s2">PyMC3 </span><span class="si">%s</span><span class="se">\n</span><span class="s2">Theano </span><span class="si">%s</span><span class="se">\n</span><span class="s2">"</span> <span class="o">%</span> <span class="p">(</span><span class="n">platform</span><span class="o">.</span><span class="n">machine</span><span class="p">(),</span> <span class="n">platform</span><span class="o">.</span><span class="n">mac_ver</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="n">sys</span><span class="o">.</span><span class="n">version</span><span class="p">[:</span><span class="mi">5</span><span class="p">],</span> <span class="n">IPython</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span> <span class="n">mkl</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span> <span class="n">pm</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span> <span class="n">theano</span><span class="o">.</span><span class="n">__version__</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>This notebook was created on an x86_64 computer running OSX 10.11.6 and using:
Python 3.6.5
IPython 6.4.0
mkl 1.1.2
NumPy 1.14.5
PyMC3 3.5.rc1
Theano 1.0.2

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Vocabulary">Vocabulary<a class="anchor-link" href="#Vocabulary">¶</a>
</h3>
<ul>
<li>
<p><strong>Likelihood</strong><br>
This is what statisticians call the probability mass (or density)
function $p(x|\theta)$ when, instead of evaluating it
for fixed parameters $\theta$ they evaluate it for
fixed observation $x$ and allow the parameters themselves
to vary across their entire domain. To make this more explicit
when talking about it, they give the function a different
name: the likelihood $\mathscr{L}(\theta|x) \equiv p(\theta|x)$.
The total area under the likelihood need not
equal one, so it must be normalized.</p>
</li>
<li>
<p><strong>Monte Carlo Method</strong><br>
The practice of using pseudo-random numbers generated in a
computer to model random events. Named for the Monte Carlo
casino in Monaco, where Stanislaw Ulam's uncle would gamble.
(Ulam is a coauthor on the 1953 Metropolis paper.)</p>
</li>
<li>
<p><strong>Markov Chain</strong><br>
A sequence of events that each satisfy the Markov property:
that whatever happens next only depends on the current state, and
is independent of prior events. A Brownian motion is one example.
It is named for the Russian mathematician Andrey Andreevich Markov.</p>
</li>
<li>
<p><strong>Markov Chain Monte Carlo (MCMC)</strong><br>
A sequence of successive Monte Carlo draws in which the starting
point of the current draw is the outcome of the last draw. The chain
steps through points in probability space. The MCMC algorithms have
a weighted preference for more likely outcomes, so the chain will
spend more of its time in the more likely regions. This means
the tail of the resulting Markov Chain will approximate the
posterior distribution, and you can draw from it like you
would draw from any computer-generated random distribution.</p>
</li>
<li>
<p><strong>Posterior</strong><br>
In the context of Bayesian statistics, this is a new distribution
that combines what you knew a priori with the observed data.
When using MCMC, the posterior is approximated by the tail end
of the sample trace.
Mathematically, you obtain the posterior from Bayes' theorem, in which
$p(x)$ is a prior of your choice, often constant, $x_\text{obs}$
is the observed data, and $\mathscr{L}$ is a likelihood of your choice.
$$P(x|x_\text{obs}) = \frac{P(x_\text{obs} | x)}{P(x_\text{obs})} p(x) = \frac{\mathscr{L}(x_\text{obs}| x)}{\int_{x}\mathscr{L}(x_\text{obs}|x) p(x) dx} p(x)$$</p>
</li>
<li>
<p><strong>Prior</strong><br>
In the context of Bayesian statistics, a distribution that reflects
what you know about a random variable prior to incorporating your
observations. Often people will just say the prior is uniform,
$p(x) \propto 1$, and normalize it out. Robert Cousins gives the example
in particle physics where the prior can be zero for negative
mass and uniform otherwise, or other choices that make sense for the
context.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Further-resources">Further resources<a class="anchor-link" href="#Further-resources">¶</a>
</h3>
<p>The following resources (in chronological order) are for people interested in the history of MCMC methods:</p>
<ul>
<li>
<a href="https://aip.scitation.org/doi/10.1063/1.1699114">Equation of State Calculations by Fast Computing Machines (paywall)</a><br>
Nicholas Metropolis and collaborators' paper starting it all.
<em>J. Chem. Phys.</em>, Vol. 21, No. 6 (June 1953) pp. 1087-1092.</li>
<li>
<a href="https://www.jstor.org/stable/2334940">Monte Carlo Sampling Methods Using Markov Chains and Their Applications</a><br>
Wilhelm Hastings's paper explaining and generalizing Metropolis's algorithm.
<em>Biometrika</em>, Vol. 57, No. 1 (April 1970), pp. 97-109.</li>
<li>
<a href="https://library.lanl.gov/cgi-bin/getfile?00326866.pdf">The Beginning of the Monte Carlo Method (pdf)</a><br>
A delightful historical account, by Nicholas Metropolis, written as part of a special newsletter honoring the scientific contributions of Stan Ulam. <em>Los Alamos Science</em>, Special Issue, 1987, pp.125-130.</li>
<li>
<a href="https://arxiv.org/pdf/1104.2210.pdf">From EM to Data Augmentation: The Emergence of MCMC Bayesian Computation in the 1980s (pdf)</a><br>
Martin Tanner and Wing Wong's fantastic survey of the history of Markov Chain Monte Carlo methods.
<em>Stat. Sci.</em>, Vol. 25, No. 4 (2010) pp. 506–516</li>
</ul>
<p>I'm new to the Bayesian approach. The following resources (in descending order of usefulness) have helped me:</p>
<ul>
<li>
<a href="https://www.astro.princeton.edu/~strauss/AST303/bayesian_paper.pdf">"Why isn't every physicist a Bayesian?" (pdf)</a><br>
☆ Choose this if you only have time for one paper. ☆<br>
Robert D. Cousins's paper is technical but understandable. It mercifully avoids the religious fervor of other papers on the topic.
<em>Am. J. Phys.</em>, Vol. 63, No. 5 (May 1995).</li>
<li>
<a href="https://www.apa.org/pubs/journals/releases/amp-amp0000191.pdf">Journal Article Reporting Standards for Quantitative Research in
Psychology: The APA Publications and Communications Board Task
Force Report</a><br>
Table 8 is about reporting Bayesian results. It's longer and more detailed than the BaSiS group checklist listed next.</li>
<li>
<a href="http://lib.stat.cmu.edu/bayesworkshop/2001/BaSis.html">Standards for Reporting of Bayesian Analyses in the Scientific Literature (no https)</a><br>
The Bayesian Standards in Science group (BaSiS) compiled a checklist in 2001 for what to include when reporting Bayesian results. Short and sweet. <a href="http://lib.stat.cmu.edu/bayesworkshop/2001/BaSisGuideline.htm">The actual checklist (no https)</a>.</li>
<li>
<a href="https://arxiv.org/abs/1411.5018">Frequentism and Bayesianism: A Python-driven Primer (pdf)</a><br>
Jake VanderPlas's 2014 paper is a summary of both the Frequentist and Bayesian philosophies. It uses accessible language and examples, and demonstrates both techniques using Python but sort of feels like it's trolling Frequentists. The Cousins paper was easier for me to understand. <em>Proc. of the 13th Python in science conf.</em> (SCIPY 2014).</li>
<li>
<a href="https://jakevdp.github.io/blog/2014/06/14/frequentism-and-bayesianism-4-bayesian-in-python/">Frequentism and Bayesianism blog post</a><br>
VanderPlas's 2014 blog post describes PyMC (the precursor to <a href="https://docs.pymc.io/">PyMC3</a>) and two other Python tools, with a lot of the examples eventually going into the above paper; for people who prefer a blog format.</li>
<li>
<a href="https://twiecki.github.io/blog/2015/11/10/mcmc-sampling/">MCMC sampling for dummies</a><br>
Thomas Wiecki's 2015 blog post that inspired this one. It's good for people who are comfortable with the statistics part of the Bayesian approach but not comfortable with the numerical methods part of MCMC. (That's actually the opposite of what I was.)</li>
</ul>
<p><em>All links in this post were accessed on or before July 29, 2018.</em></p>

</div>
</div>
</div>
    </div>
  </div>

    </div>
    <aside class="postpromonav"><span class="hidden-print">
      <a href="https://twitter.com/share?ref_src=twsrc%5Etfw" class="twitter-share-button" data-show-count="false">Tweet</a>
      <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></span>
    <span class="hidden-print">
      <script src="//platform.linkedin.com/in.js" type="text/javascript"> lang: en_US</script><script type="IN/Share" data-url="https://tanyaschlusser.github.io/posts/mcmc-and-the-ising-model/"></script></span>
    <nav><ul itemprop="keywords" class="tags">
<li>Filed under:  <a class="tag p-category" href="../../categories/cat_methods/" rel="category"> Methods</a>
</li>
            <li><a class="tag p-category" href="../../categories/bayesian/" rel="tag">bayesian</a></li>
            <li><a class="tag p-category" href="../../categories/mcmc/" rel="tag">mcmc</a></li>
            <li><a class="tag p-category" href="../../categories/pymc3/" rel="tag">pymc3</a></li>
      </ul>
<ul class="pager hidden-print">
<li>
            <span class="disabled"><span aria-hidden="true">‹ </span>Older</span>
        </li>
        <li>
            <a href="../property-tax-cook-county/" rel="next" class="next" title="Modeling property tax assessment in Cook County">Newer<span aria-hidden="true"> ›</span></a>
        </li>
    </ul></nav></aside></article><aside class="bio">
    Thank you for reading! <span class="red">❤ </span> I'm a developer based in
    <a href="https://chipy.org" title="My home Python user group!">Chicago</a>.
    I'm not working right now because my Mom is sick, but we can connect on
    <a href="https://www.linkedin.com/in/tanyatickel" title="Say you read my blog so I know you're not a robot.">LinkedIn</a>, or
    you can find my work on <a href="https://github.com/tanyaschlusser" title="Where this site is hosted...">GitHub</a>.
    I'm on <a href="https://twitter.com/tanyaschlusser">Twitter</a> too, but don't use it much.
</aside><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0-beta/katex.min.js" integrity="sha256-mxaM9VWtRj1wBtn50/EDUUe4m3t39ExE+xEPyrxVB8I=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0-beta/contrib/auto-render.min.js" integrity="sha256-9uFJqVHnc71lPswxPcpJP49zqhdqp7DFqX68yHs358I=" crossorigin="anonymous"></script><script>
                renderMathInElement(document.body,
                    {
                        
delimiters: [
    {left: "$$", right: "$$", display: true},
    {left: "\\[", right: "\\]", display: true},
    {left: "$", right: "$", display: false},
    {left: "\\(", right: "\\)", display: false}
]

                    }
                );
            </script></main><footer id="footer"><p class="light-sans">© Tanya Schlusser · Subscribe via <a href="../../rss.xml">RSS</a> · Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a> using a <a href="https://github.com/tanyaschlusser/tanyaschlusser.github.io/tree/src">custom theme</a> </p>
            
        </footer>
</body>
</html>
